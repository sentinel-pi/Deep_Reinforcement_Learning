{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f8f50fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from Buffers.ExperienceReplayBuffer import ExperienceReplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d23e1",
   "metadata": {},
   "source": [
    "<center> <h1> Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce86656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13 \n",
    "GAMMA = 0.995\n",
    "LR = 0.01\n",
    "STEPS = 1000\n",
    "BATCH_SIZE = 64\n",
    "EPISODES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eac3b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 17)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Walker2d-v5\",render_mode = \"rgb_array\")\n",
    "RecordVideo(env,\"../Results/PolicyBased\",lambda x: x%25 == 0 and x != 0 , fps=15 )\n",
    "actionNum = env.action_space.shape[0] \n",
    "stateNum = env.observation_space.shape[0]\n",
    "print((actionNum,stateNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e991fdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8442168068813372\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env.reset()\n",
    "for steps in range(1):\n",
    "    action = env.action_space.sample()\n",
    "    _,rewards,terminated,truncated,_=env.step(action)\n",
    "    print(rewards)\n",
    "    time.sleep(0.1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66b044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self,stateNum,h1,h2,h3,actionNum):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(stateNum + actionNum,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,1)\n",
    "    def forward(self,state,action):\n",
    "        x = torch.hstack((state,action))\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        Q = torch.relu(self.fc4(x))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d04acc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self,stateNum,h1,h2,h3,actionNum):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(stateNum,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,actionNum)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        A = torch.tanh(self.fc4(x))\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef79928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(SEED)\n",
    "critic        = Critic(stateNum,400,200,100,actionNum).to(device)\n",
    "actor         = Actor(stateNum,400,200,100,actionNum).to(device)\n",
    "critic_target = Critic(stateNum,400,200,100,actionNum).to(device)\n",
    "actor_target  = Actor(stateNum,400,200,100,actionNum).to(device)\n",
    "critic_target.load_state_dict(critic.state_dict())\n",
    "actor_target.load_state_dict(actor.state_dict())\n",
    "\n",
    "critic_criterion = nn.MSELoss()\n",
    "# actor_criterion = \n",
    "critic_optim =  Adam(critic.parameters(),LR)\n",
    "actor_optim= Adam(actor.parameters(),LR)\n",
    "\n",
    "buffer = ExperienceReplay(BATCH_SIZE,device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "89fa833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-0.1702, -0.0086,  0.1295,  ...,  0.1957, -0.0211, -0.0404],\n",
       "                      [ 0.1335,  0.1998, -0.0718,  ..., -0.0370,  0.1102,  0.1365],\n",
       "                      [ 0.1876, -0.0603, -0.1387,  ..., -0.0537,  0.0341,  0.1460],\n",
       "                      ...,\n",
       "                      [ 0.2035,  0.0252,  0.0173,  ..., -0.1964,  0.1715, -0.1880],\n",
       "                      [-0.1487,  0.1465,  0.0671,  ..., -0.0907, -0.0044, -0.1642],\n",
       "                      [-0.0393,  0.1688, -0.1711,  ...,  0.0992, -0.1128, -0.0826]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-6.3814e-02, -1.3460e-01, -1.7037e-01, -1.3998e-01,  1.5878e-01,\n",
       "                       1.3988e-01,  1.8016e-01,  1.3112e-01,  5.7631e-02, -1.1514e-01,\n",
       "                      -1.9691e-01,  1.3262e-01,  7.6445e-03,  1.1214e-01,  7.2446e-03,\n",
       "                       1.4982e-01, -1.7051e-01,  3.7485e-02, -1.8250e-01, -1.6072e-01,\n",
       "                      -4.0644e-02,  2.4760e-02, -1.8671e-01,  2.9729e-02, -1.3241e-02,\n",
       "                      -4.9746e-02, -1.1639e-01, -1.6794e-01, -1.7076e-01, -1.4133e-02,\n",
       "                      -9.7811e-05, -1.4137e-01,  1.3645e-01,  1.9366e-02, -2.9926e-02,\n",
       "                      -2.7577e-02, -7.5414e-02,  1.9204e-01,  8.8153e-02, -5.8616e-03,\n",
       "                       9.2448e-02, -5.5958e-03,  1.2456e-01,  1.6143e-01, -1.7606e-01,\n",
       "                       1.1844e-01, -1.5125e-02, -5.6662e-02,  2.0310e-01,  6.6356e-02,\n",
       "                      -1.2723e-01, -1.1688e-01, -1.4170e-01, -1.4527e-01,  1.5295e-01,\n",
       "                      -1.8897e-01, -2.0519e-01, -1.1504e-01, -6.2578e-03,  1.0086e-01,\n",
       "                       1.2937e-01, -1.1433e-01, -8.2979e-02, -9.3693e-02, -9.2450e-02,\n",
       "                      -2.1660e-02, -4.6358e-02, -1.4783e-02, -1.7113e-01,  1.9930e-01,\n",
       "                       9.9384e-02, -1.0059e-01, -3.5988e-02,  5.1837e-02,  1.1397e-01,\n",
       "                      -1.9985e-01,  1.4174e-01, -7.2887e-02, -2.0743e-01, -4.3615e-02,\n",
       "                      -1.6442e-01,  2.4209e-02, -8.3451e-02,  1.6479e-01,  4.6656e-03,\n",
       "                       1.6748e-01, -1.6103e-01, -1.8100e-01, -9.7196e-02, -3.2209e-03,\n",
       "                       1.1805e-01,  9.4939e-02,  6.8246e-03,  8.9826e-02, -1.5204e-01,\n",
       "                      -1.8000e-01, -1.9679e-01, -1.1020e-01, -1.0943e-01, -1.8332e-01,\n",
       "                      -1.5177e-01,  1.2873e-02, -2.0390e-01,  7.8663e-02,  6.7733e-03,\n",
       "                       1.6692e-01,  1.6992e-01,  2.0009e-01,  1.9956e-01,  1.3222e-01,\n",
       "                      -1.5052e-01,  1.7117e-01,  9.1453e-02, -1.2813e-01, -5.1588e-02,\n",
       "                       1.8860e-01,  1.7786e-01,  1.8654e-01,  1.4655e-01, -2.0377e-01,\n",
       "                       2.0645e-01,  1.9685e-01, -1.0768e-01, -1.0734e-01, -3.9082e-02,\n",
       "                       4.3822e-02, -7.6344e-02,  1.8279e-01, -2.0114e-02, -1.0975e-01,\n",
       "                      -2.0504e-01,  2.7292e-02,  1.7417e-01, -8.8123e-02,  1.1851e-01,\n",
       "                       8.6379e-02, -3.0522e-02,  1.0849e-01, -5.3871e-02,  2.5291e-02,\n",
       "                       4.0052e-02,  5.8728e-02,  1.3334e-01, -3.9861e-03, -1.6580e-02,\n",
       "                      -1.7369e-01, -1.1130e-01, -2.0311e-01, -1.8286e-01,  9.6377e-02,\n",
       "                      -9.4099e-02,  8.9638e-03, -1.9175e-01,  9.2323e-02,  8.8828e-02,\n",
       "                       6.4261e-02, -1.7786e-01,  2.8670e-02,  9.1631e-02,  8.2019e-02,\n",
       "                      -9.0424e-02,  1.8072e-01,  9.3390e-02,  4.8940e-02,  1.2497e-01,\n",
       "                       1.8962e-01, -1.4216e-01, -1.3282e-01, -9.3709e-02,  2.4652e-02,\n",
       "                      -1.8887e-02, -1.9842e-01,  1.7315e-01, -9.1683e-02, -1.8895e-01,\n",
       "                       2.0777e-01, -8.2505e-02, -1.6837e-01,  1.3892e-01, -6.6200e-02,\n",
       "                      -2.5914e-02,  1.0922e-01, -1.8735e-02,  2.5096e-02, -3.4260e-02,\n",
       "                       1.3103e-01, -1.4497e-01, -1.9822e-02, -2.0111e-01,  8.8145e-02,\n",
       "                       4.4562e-02, -2.0760e-01,  1.7185e-01, -1.1045e-01, -1.8815e-01,\n",
       "                       3.9541e-02,  7.2640e-02, -8.3033e-03, -2.0649e-01, -1.5429e-01,\n",
       "                       3.2494e-02, -1.3122e-01,  1.0062e-01,  1.5041e-01, -4.1204e-02,\n",
       "                       1.8550e-01, -1.5269e-01, -1.7613e-01, -4.4453e-02,  9.0538e-02,\n",
       "                       8.8075e-02,  9.9468e-02, -1.5478e-01, -2.0213e-01,  7.3605e-02,\n",
       "                       1.4385e-01,  1.1613e-01, -1.3821e-01, -1.9075e-01,  1.9449e-01,\n",
       "                      -6.6828e-02,  9.3562e-02, -3.0720e-02,  5.9991e-02,  1.7610e-01,\n",
       "                       1.2863e-01, -7.4803e-02,  1.2011e-01,  6.7339e-02,  1.6887e-01,\n",
       "                      -7.6676e-02, -9.9779e-02, -1.3375e-04, -7.2597e-02,  1.1947e-01,\n",
       "                      -1.6588e-01,  5.7400e-02, -1.5356e-01, -1.4570e-01,  6.1595e-02,\n",
       "                       1.4273e-01, -2.4566e-02, -1.0048e-01,  2.1686e-02,  1.0144e-01,\n",
       "                      -1.9128e-01,  8.8943e-02,  1.1602e-01, -1.6182e-01, -3.2092e-02,\n",
       "                      -4.5209e-02, -1.1552e-01,  1.7938e-01, -9.7375e-02, -1.9720e-02,\n",
       "                       6.1286e-02,  8.9867e-02, -2.0537e-01,  1.8408e-01,  5.9671e-02,\n",
       "                       2.0215e-01,  3.8653e-03,  1.0089e-01,  1.2215e-01,  1.7871e-02,\n",
       "                       1.3105e-01,  1.9812e-01, -1.4323e-01, -2.0543e-01, -4.0651e-02,\n",
       "                      -1.9993e-01,  1.0549e-01, -2.0084e-01,  1.3475e-01,  1.1771e-02,\n",
       "                       1.7557e-01, -1.1320e-02, -1.9233e-01,  2.9108e-02,  1.7683e-01,\n",
       "                      -2.0292e-03, -3.5498e-02,  1.9105e-01, -3.2205e-02,  8.0075e-02,\n",
       "                      -1.1363e-01, -1.3707e-01, -1.0051e-01, -4.7571e-03, -1.7779e-01,\n",
       "                      -1.9099e-01, -9.3884e-02, -7.4509e-02, -6.7607e-02, -9.7175e-03,\n",
       "                       2.0011e-01,  1.5769e-01, -6.0044e-02,  1.7381e-01, -8.4893e-02,\n",
       "                      -1.9597e-01, -9.8648e-02, -8.1165e-02, -2.0436e-01,  5.9865e-02,\n",
       "                      -3.0538e-02, -1.2217e-01, -6.7779e-02, -8.4102e-02,  1.3707e-01,\n",
       "                       7.5220e-04, -1.2804e-01,  5.2499e-02, -6.9746e-02, -8.9323e-03,\n",
       "                      -8.9293e-02, -1.0183e-03,  1.7741e-01,  4.9460e-02, -2.8633e-02,\n",
       "                       1.7947e-01,  1.7892e-01,  1.7075e-01,  4.7829e-02,  6.0257e-02,\n",
       "                       1.6079e-01, -1.4202e-01,  8.4203e-02, -1.9272e-01,  3.8255e-02,\n",
       "                       8.9264e-02,  1.1711e-01, -1.6174e-01,  8.5706e-02, -6.6678e-02,\n",
       "                       1.8959e-01,  1.8134e-01,  1.4587e-01, -7.4071e-02, -8.8376e-02,\n",
       "                      -1.4942e-01,  1.5195e-01, -1.3535e-01,  1.8231e-01,  1.1161e-01,\n",
       "                       9.5469e-02,  8.3408e-02,  3.1018e-02, -1.4465e-01,  8.7055e-02,\n",
       "                       1.3626e-01, -1.3713e-01,  2.0480e-01, -4.8377e-02,  1.5776e-01,\n",
       "                       1.6839e-01,  5.5806e-02, -3.4468e-02,  8.1525e-02,  1.9163e-01,\n",
       "                       1.9673e-01,  1.1176e-01, -1.2143e-01, -2.0085e-01, -2.0645e-01,\n",
       "                      -1.2375e-01,  1.2234e-01,  1.0332e-01,  8.2950e-03, -2.0093e-01,\n",
       "                      -8.5060e-03, -3.8126e-02,  7.9837e-02, -5.7691e-02,  3.9849e-03,\n",
       "                      -3.2381e-02,  2.0039e-01, -1.4200e-01, -1.8627e-01, -1.6732e-01,\n",
       "                      -7.4947e-02, -4.5530e-02,  5.0501e-02, -9.2756e-02, -1.9113e-01,\n",
       "                       1.2423e-01,  1.1241e-01, -1.4149e-01, -1.3947e-01,  1.4326e-01,\n",
       "                       8.5182e-02, -1.4653e-01, -1.4134e-01, -8.0584e-02,  1.4641e-01,\n",
       "                       8.9461e-02, -3.1297e-02, -5.1409e-02, -2.7211e-02, -1.2766e-01],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0393, -0.0389, -0.0385,  ...,  0.0206,  0.0354, -0.0316],\n",
       "                      [ 0.0282,  0.0257, -0.0396,  ...,  0.0410,  0.0440, -0.0218],\n",
       "                      [-0.0317, -0.0360,  0.0263,  ..., -0.0023, -0.0254,  0.0010],\n",
       "                      ...,\n",
       "                      [-0.0147,  0.0005,  0.0347,  ..., -0.0226, -0.0033, -0.0284],\n",
       "                      [ 0.0084, -0.0490,  0.0100,  ..., -0.0194,  0.0034, -0.0101],\n",
       "                      [ 0.0189,  0.0109,  0.0447,  ..., -0.0403,  0.0436,  0.0043]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 3.7868e-02,  2.2560e-02,  3.7813e-02, -2.9246e-02, -4.4409e-02,\n",
       "                      -7.0839e-03, -3.1509e-02,  2.4738e-02, -3.1062e-02, -1.9716e-02,\n",
       "                      -3.4852e-02,  5.7623e-03, -1.1845e-02,  2.5187e-02, -4.9906e-02,\n",
       "                       1.1359e-04,  3.1205e-02,  4.1350e-02,  1.9375e-02, -3.2228e-02,\n",
       "                       4.5737e-02,  3.4493e-02, -2.3144e-02, -4.4348e-02,  4.1776e-02,\n",
       "                       4.7009e-02, -8.5797e-04, -4.8844e-02, -3.8880e-02, -8.9269e-03,\n",
       "                      -2.8055e-02, -3.8493e-02, -2.5636e-02, -2.1158e-02, -2.1088e-03,\n",
       "                      -2.1486e-02, -1.5111e-02,  3.3004e-02, -2.4415e-02, -1.2310e-02,\n",
       "                      -3.4984e-02,  3.3831e-02, -8.6846e-03, -8.6135e-03,  4.1991e-02,\n",
       "                       1.6209e-03,  8.9209e-03, -2.0286e-02,  4.5236e-02,  4.4690e-02,\n",
       "                      -4.9561e-02, -8.4906e-03,  1.0632e-02,  2.4280e-02,  1.2469e-02,\n",
       "                       1.4097e-02, -1.4576e-03,  2.5178e-02,  3.3617e-02,  4.2154e-02,\n",
       "                       2.1481e-02,  4.1603e-02, -1.2606e-02, -4.7444e-02, -5.1654e-03,\n",
       "                      -8.9396e-03, -2.1938e-02, -3.4950e-02,  5.0991e-03, -8.0333e-03,\n",
       "                       3.9857e-02, -4.2159e-02, -2.3180e-02,  4.9464e-02, -1.0665e-02,\n",
       "                       2.1386e-02, -9.1579e-03, -1.6225e-02,  2.6638e-02,  2.2106e-02,\n",
       "                      -8.3519e-03, -3.1541e-03,  4.6560e-02,  7.6824e-03,  1.5314e-02,\n",
       "                       1.9789e-03, -3.1590e-02,  1.5126e-03, -3.8329e-02,  3.7457e-02,\n",
       "                      -1.3390e-02,  2.8284e-03,  1.5991e-02, -3.5761e-02,  2.9753e-02,\n",
       "                       2.5475e-02, -2.4067e-02, -4.0291e-03,  3.5384e-02,  1.0892e-02,\n",
       "                       2.4318e-02,  3.7515e-02,  3.1974e-02, -5.5613e-03,  3.9585e-02,\n",
       "                       1.6936e-02,  3.7626e-02, -8.2106e-03, -3.1604e-02, -1.6332e-02,\n",
       "                      -1.9588e-02,  2.7978e-02, -3.1218e-02, -4.7876e-02,  2.4958e-02,\n",
       "                       3.1843e-02, -3.4993e-02, -2.6468e-02,  4.8287e-02, -3.9004e-03,\n",
       "                      -3.1226e-02, -2.3570e-02,  9.6905e-03, -3.7426e-02,  4.4864e-02,\n",
       "                       3.4080e-02, -5.1737e-03, -4.0907e-02, -2.0402e-02, -1.8666e-02,\n",
       "                      -2.8531e-03,  2.2414e-02,  4.5804e-02,  8.6226e-05, -1.7569e-02,\n",
       "                       2.7462e-02,  4.1766e-02, -1.0291e-02,  1.0256e-02,  4.0790e-02,\n",
       "                      -2.9324e-02,  4.1806e-02,  3.7194e-02,  3.3753e-02,  3.9013e-02,\n",
       "                       3.1268e-02,  1.5920e-02,  3.4209e-02,  3.1507e-02, -9.2387e-03,\n",
       "                      -2.7181e-02,  7.3292e-03, -1.6417e-02,  3.9116e-02,  3.5696e-02,\n",
       "                      -4.1937e-02, -5.1111e-03, -1.6858e-02,  4.0713e-02,  3.3343e-02,\n",
       "                      -2.1766e-02, -3.8090e-02, -4.6276e-02, -2.0373e-02,  5.0502e-03,\n",
       "                      -1.8701e-02,  2.4377e-02,  1.9005e-02,  4.7768e-02,  2.9931e-02,\n",
       "                      -1.3327e-02,  4.9837e-02, -6.0562e-03,  4.8963e-02,  1.1350e-02,\n",
       "                      -4.6116e-02,  3.5803e-02,  2.2628e-03, -2.0320e-02,  3.5333e-02,\n",
       "                      -4.8536e-02, -1.8328e-02, -1.9991e-02,  4.1870e-02,  2.2314e-02,\n",
       "                       4.5413e-02, -1.0588e-02,  3.6317e-02,  4.4522e-02,  3.1379e-02,\n",
       "                       3.2117e-02, -3.4338e-04,  4.7462e-03,  3.3489e-02,  2.0429e-02,\n",
       "                      -3.4630e-02, -4.9856e-03,  5.0848e-03, -2.1732e-02,  4.4723e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0216,  0.0013,  0.0016,  ..., -0.0480, -0.0505, -0.0611],\n",
       "                      [-0.0617,  0.0669,  0.0673,  ..., -0.0469, -0.0109, -0.0665],\n",
       "                      [ 0.0637,  0.0424, -0.0436,  ..., -0.0125,  0.0227, -0.0152],\n",
       "                      ...,\n",
       "                      [-0.0162,  0.0299, -0.0614,  ...,  0.0682,  0.0259,  0.0035],\n",
       "                      [-0.0291, -0.0670, -0.0045,  ..., -0.0103, -0.0309, -0.0003],\n",
       "                      [-0.0060, -0.0362, -0.0030,  ..., -0.0295, -0.0515, -0.0329]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.0158,  0.0464,  0.0213,  0.0150,  0.0578,  0.0087,  0.0235, -0.0699,\n",
       "                       0.0533, -0.0140,  0.0346, -0.0224, -0.0161,  0.0164, -0.0010, -0.0162,\n",
       "                       0.0518,  0.0580,  0.0024,  0.0061,  0.0528,  0.0590, -0.0501,  0.0539,\n",
       "                      -0.0563,  0.0613,  0.0157, -0.0518,  0.0496,  0.0244,  0.0328,  0.0611,\n",
       "                       0.0544, -0.0262, -0.0445, -0.0421, -0.0703, -0.0180,  0.0177, -0.0215,\n",
       "                      -0.0012, -0.0105,  0.0519,  0.0450, -0.0100, -0.0490,  0.0260, -0.0495,\n",
       "                       0.0372,  0.0652,  0.0650,  0.0230,  0.0601, -0.0373,  0.0633,  0.0512,\n",
       "                      -0.0668,  0.0597, -0.0534,  0.0261, -0.0217, -0.0007,  0.0323, -0.0189,\n",
       "                       0.0209, -0.0662,  0.0461, -0.0562, -0.0345,  0.0024,  0.0558,  0.0115,\n",
       "                       0.0661, -0.0257, -0.0044,  0.0063, -0.0592, -0.0196,  0.0181, -0.0197,\n",
       "                       0.0210,  0.0415,  0.0391, -0.0667,  0.0353,  0.0427,  0.0474, -0.0075,\n",
       "                       0.0315, -0.0655,  0.0265,  0.0163,  0.0578,  0.0144,  0.0660,  0.0541,\n",
       "                      -0.0186,  0.0635, -0.0143, -0.0375], device='cuda:0')),\n",
       "             ('fc4.weight',\n",
       "              tensor([[ 0.0957, -0.0056,  0.0504, -0.0396,  0.0176, -0.0176,  0.0784,  0.0241,\n",
       "                        0.0650,  0.0765,  0.0713, -0.0666,  0.0872, -0.0339, -0.0216, -0.0415,\n",
       "                        0.0934, -0.0085,  0.0139,  0.0057, -0.0239, -0.0730,  0.0315,  0.0599,\n",
       "                       -0.0284, -0.0785, -0.0979, -0.0909,  0.0923, -0.0764, -0.0830,  0.0923,\n",
       "                       -0.0640, -0.0413,  0.0334, -0.0863,  0.0273,  0.0093,  0.0588,  0.0128,\n",
       "                       -0.0013, -0.0471,  0.0507, -0.0766,  0.0242, -0.0268,  0.0005,  0.0057,\n",
       "                        0.0956,  0.0672, -0.0324,  0.0500, -0.0397,  0.0595, -0.0547,  0.0274,\n",
       "                        0.0636,  0.0056,  0.0347, -0.0842, -0.0897, -0.0074, -0.0498,  0.0463,\n",
       "                        0.0585, -0.0222, -0.0845,  0.0155, -0.0794, -0.0471,  0.0259, -0.0642,\n",
       "                        0.0350,  0.0385,  0.0593, -0.0404,  0.0135,  0.0475,  0.0542,  0.0518,\n",
       "                        0.0358, -0.0612, -0.0229, -0.0303, -0.0983, -0.0330, -0.0799,  0.0253,\n",
       "                       -0.0715,  0.0608,  0.0315, -0.0240, -0.0663, -0.0724, -0.0006,  0.0604,\n",
       "                       -0.0839, -0.0463,  0.0624, -0.0503]], device='cuda:0')),\n",
       "             ('fc4.bias', tensor([0.0486], device='cuda:0'))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critic.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1e33adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12043589, -0.27729373, -0.20291126, -1.47787215, -1.71265115,\n",
       "        1.17501457])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =np.random.randn(6)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ea4cba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12043589, -0.2       , -0.2       , -0.2       , -0.2       ,\n",
       "        0.2       ])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.clip(-0.2,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e5ac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_update(online,target,tau):\n",
    "    online_dict = online.state_dict()\n",
    "    target_dict = target.state_dict()\n",
    "    for key in online_dict.keys():\n",
    "        target_dict[key]= tau*online_dict[key] + (1-tau) * target_dict[key]\n",
    "    target.load_state_dict(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7840ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 | Reward: -17.875495222663634\n",
      "Episode: 1 | Reward: -82.92580356312604\n",
      "Episode: 2 | Reward: -70.63997108529537\n",
      "Episode: 3 | Reward: -83.34905884382066\n",
      "Episode: 4 | Reward: -83.75135154104781\n",
      "Episode: 5 | Reward: -70.31006791801812\n",
      "Episode: 6 | Reward: -74.07208112865709\n",
      "Episode: 7 | Reward: -83.87745477775897\n",
      "Episode: 8 | Reward: -85.83852711349287\n",
      "Episode: 9 | Reward: -77.79021846725604\n",
      "Episode: 10 | Reward: -71.98237357733184\n",
      "Episode: 11 | Reward: -77.47686053588518\n",
      "Episode: 12 | Reward: -84.68253058023357\n",
      "Episode: 13 | Reward: -83.7435708141066\n",
      "Episode: 14 | Reward: -86.19307015612222\n",
      "Episode: 15 | Reward: -81.16401628219874\n",
      "Episode: 16 | Reward: -82.53479874381728\n",
      "Episode: 17 | Reward: -81.84203693634754\n",
      "Episode: 18 | Reward: -84.73082353046517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m critic_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m critic_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 29\u001b[0m \u001b[43mcritic_optim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m actor_optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mcritic(old_state,actor(old_state))\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\optim\\adam.py:510\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_state_steps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_cpu:\n\u001b[1;32m--> 510\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_foreach_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice_state_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    512\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_state_steps, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tau = 0.005\n",
    "rewards = []\n",
    "for episode in range(EPISODES):\n",
    "    old_observation,info =env.reset(seed=SEED)\n",
    "    cumulative_reward = 0\n",
    "    for step in range(STEPS):\n",
    "        old_observation=torch.Tensor(old_observation).reshape(1,-1).to(device)\n",
    "        action = actor(old_observation).cpu().detach().numpy().squeeze()\n",
    "        exploration_noise = np.random.randn(action.shape[0])*0.1\n",
    "        exploration_noise=exploration_noise.clip(-0.3,0.3)\n",
    "        old_observation=old_observation.cpu().detach().numpy().squeeze()\n",
    "        new_observation,reward,terminated,truncated,info = env.step(action+exploration_noise)\n",
    "        cumulative_reward+=reward\n",
    "        done = terminated or truncated\n",
    "        buffer.append(old_observation,action,reward,new_observation,done)\n",
    "        rewards.append(reward)\n",
    "        old_observation = new_observation\n",
    "        if(buffer.size() >= BATCH_SIZE):\n",
    "            old_state,old_action,reward,new_state,done=buffer.sample(BATCH_SIZE)\n",
    "            reward = reward.reshape(-1,1)\n",
    "            done = done.reshape(-1,1)   \n",
    "            y_hat = critic(old_state,actor(old_state))\n",
    "            with torch.no_grad():\n",
    "                y = reward + GAMMA * critic_target(new_state,actor_target(new_state)) * (1 - done)\n",
    "            \n",
    "            critic_loss =critic_criterion(y,y_hat)    \n",
    "            critic_optim.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            critic_optim.step()\n",
    "            actor_optim.zero_grad()\n",
    "            actor_loss = -critic(old_state,actor(old_state)).mean()\n",
    "            actor_loss.backward()\n",
    "            actor_optim.step()\n",
    "            with torch.no_grad():\n",
    "                soft_update(critic,critic_target,tau)\n",
    "                soft_update(actor,actor_target,tau)\n",
    "        if(truncated or terminated):\n",
    "            break;\n",
    "    print(f\"Episode: {episode} | Reward: {cumulative_reward}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af9e48",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e01d0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
