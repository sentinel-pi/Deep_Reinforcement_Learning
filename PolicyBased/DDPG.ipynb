{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f50fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from Buffers.ExperienceReplayBuffer import ExperienceReplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4d23e1",
   "metadata": {},
   "source": [
    "<center> <h1> Constants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce86656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 13 \n",
    "GAMMA = 0.995\n",
    "LR = 0.01\n",
    "STEPS = 1000\n",
    "BATCH_SIZE = 64\n",
    "EPISODES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac3b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\gymnasium\\wrappers\\rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\pooya\\Projects\\Programming\\Artificial intelligence\\Reinforcement Learning\\Reinforement Learning\\Results\\PolicyBased folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Walker2d-v5\",render_mode = \"rgb_array\")\n",
    "RecordVideo(env,\"../Results/PolicyBased\",lambda x: x%25 == 0 and x != 0 , fps=15 )\n",
    "actionNum = env.action_space.shape[0] \n",
    "stateNum = env.observation_space.shape[0]\n",
    "print((actionNum,stateNum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e991fdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7509056997256911\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "env.reset()\n",
    "for steps in range(1):\n",
    "    action = env.action_space.sample()\n",
    "    _,rewards,terminated,truncated,_=env.step(action)\n",
    "    print(rewards)\n",
    "    time.sleep(0.1)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66b044d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self,stateNum,h1,h2,h3,actionNum):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(stateNum + actionNum,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,1)\n",
    "    def forward(self,state,action):\n",
    "        x = torch.vstack(state,action)\n",
    "        print(x.shape)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        Q = torch.relu(self.fc4(x))\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d04acc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self,stateNum,h1,h2,h3,actionNum):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(stateNum,h1)\n",
    "        self.fc2 = nn.Linear(h1,h2)\n",
    "        self.fc3 = nn.Linear(h2,h3)\n",
    "        self.fc4 = nn.Linear(h3,actionNum)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        A = torch.tanh(self.fc4(x))\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef79928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch.manual_seed(SEED)\n",
    "critic        = Critic(stateNum,400,200,100,actionNum).to(device)\n",
    "actor         = Actor(stateNum,400,200,100,actionNum).to(device)\n",
    "critic_target = Critic(stateNum,400,200,100,actionNum).to(device)\n",
    "actor_target  = Actor(stateNum,400,200,100,actionNum).to(device)\n",
    "critic_target.load_state_dict(critic.state_dict())\n",
    "actor_target.load_state_dict(actor.state_dict())\n",
    "\n",
    "critic_criterion = nn.MSELoss()\n",
    "# actor_criterion = \n",
    "critic_optim =  Adam(critic.parameters(),LR)\n",
    "actor_optim= Adam(actor.parameters(),LR)\n",
    "\n",
    "buffer = ExperienceReplay(BATCH_SIZE,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fa833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([123]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b7840ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m old_state,old_action,reward,new_state,done\u001b[38;5;241m=\u001b[39mbuffer\u001b[38;5;241m.\u001b[39msample(BATCH_SIZE)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(reward\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m y \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m GAMMA \u001b[38;5;241m*\u001b[39m critic_target(new_state,\u001b[43mactor_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_state\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m critic(old_state,actor(old_state))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_hat\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m, in \u001b[0;36mActor.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[1;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x))\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc3(x))\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pooya\\miniconda3\\envs\\ai\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "for episode in range(1):\n",
    "    old_observation,info =env.reset(seed=SEED)\n",
    "    rewards = []\n",
    "    for step in range(65):\n",
    "        old_observation=torch.Tensor(old_observation).reshape(1,-1).to(device)\n",
    "        action = actor(old_observation).cpu().detach().numpy().squeeze()\n",
    "        old_observation=old_observation.cpu().detach().numpy().squeeze()\n",
    "        new_observation,reward,terminated,truncated,info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        buffer.append(old_observation,action,reward,new_observation,done)\n",
    "        rewards.append(reward)\n",
    "        old_observation = new_observation\n",
    "        if(buffer.size() >= BATCH_SIZE):\n",
    "            old_state,old_action,reward,new_state,done=buffer.sample(BATCH_SIZE)\n",
    "            print(reward.shape)\n",
    "            y = rewards + GAMMA * critic_target(new_state,actor_target(new_state))\n",
    "            y_hat = critic(old_state,actor(old_state))\n",
    "            print(y_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ac799",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor().tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
